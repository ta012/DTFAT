
Using seed 56
I am process 30007, running on cvplws262: starting (Thu Aug 17 17:19:46 2023)
now train a audio spectrogram transformer model
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process audioset
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 527

val dataset size 18886 

in stem stride 1 same pad  1216
in stem stride 2 same pad  73792

dpr  [[0.0, 0.030000001192092896], [0.06000000238418579, 0.09000000357627869], [0.12000000476837158, 0.15000000596046448, 0.18000000715255737, 0.21000000834465027, 0.24000000953674316], [0.27000001072883606, 0.30000001192092896]]
window_size  (8, 8)
In stride 2 window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size  (8, 8)
In stride 2 window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size  (8, 8)
In stride 2 window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size_time,window_size_freq  (6, 3) (3, 6)
window_size  (8, 4)
In stride 2 window_size_time,window_size_freq  (4, 3) (3, 4)
window_size_time,window_size_freq  (4, 3) (3, 4)
 Loading ImgNet Pretrained weight 

 load_from  hf-hub timm/maxvit_small_tf_384.in1k

cached_file  absolute-path/pytorch_home/hub/models--timm--maxvit_small_tf_384.in1k/snapshots/1a3002966ada62604bbc6e0f6336b8eec288e3fa/pytorch_model.bin

 pop head.fc.weight	head.fc.bias
averaging input channel 3 kernel channel 1 

stem kernel channel 1 averaged 
Stem param stem.conv1.weight weight torch.Size([64, 1, 3, 3])
Updating after reshaping stem.conv1_t.weight torch.Size([64, 1, 6, 3])
Updating after reshaping stem.conv1_f.weight torch.Size([64, 1, 3, 6])
Stem param stem.conv1.bias weight torch.Size([64])
Updating without reshaping stem.conv1_t.bias torch.Size([64])
Updating without reshaping stem.conv1_f.bias torch.Size([64])
Stem param stem.norm1.weight weight torch.Size([64])
Updating without reshaping stem.norm1_t.weight torch.Size([64])
Updating without reshaping stem.norm1_f.weight torch.Size([64])
Stem param stem.norm1.bias weight torch.Size([64])
Updating without reshaping stem.norm1_t.bias torch.Size([64])
Updating without reshaping stem.norm1_f.bias torch.Size([64])
Stem param stem.norm1.running_mean weight torch.Size([64])
Updating without reshaping stem.norm1_t.running_mean torch.Size([64])
Updating without reshaping stem.norm1_f.running_mean torch.Size([64])
Stem param stem.norm1.running_var weight torch.Size([64])
Updating without reshaping stem.norm1_t.running_var torch.Size([64])
Updating without reshaping stem.norm1_f.running_var torch.Size([64])
Stem param stem.norm1.num_batches_tracked weight torch.Size([])
Updating without reshaping stem.norm1_t.num_batches_tracked torch.Size([])
Updating without reshaping stem.norm1_f.num_batches_tracked torch.Size([])
Stem param stem.conv2.weight weight torch.Size([64, 64, 3, 3])
Updating after reshaping stem.conv2_t.weight torch.Size([64, 64, 6, 3])
Updating after reshaping stem.conv2_f.weight torch.Size([64, 64, 3, 6])
Stem param stem.conv2.bias weight torch.Size([64])
Updating without reshaping stem.conv2_t.bias torch.Size([64])
Updating without reshaping stem.conv2_f.bias torch.Size([64])

Updating key ('stages.0.blocks.0.conv.conv2_kxk.weight', 'stages.0.blocks.0.conv.conv2_kxk_t.weight', 'stages.0.blocks.0.conv.conv2_kxk_f.weight')
Updating after reshaping stages.0.blocks.0.conv.conv2_kxk_t.weight torch.Size([384, 1, 6, 3])
Updating after reshaping stages.0.blocks.0.conv.conv2_kxk_f.weight torch.Size([384, 1, 3, 6])

Updating key ('stages.0.blocks.1.conv.conv2_kxk.weight', 'stages.0.blocks.1.conv.conv2_kxk_t.weight', 'stages.0.blocks.1.conv.conv2_kxk_f.weight')
Updating after reshaping stages.0.blocks.1.conv.conv2_kxk_t.weight torch.Size([384, 1, 6, 3])
Updating after reshaping stages.0.blocks.1.conv.conv2_kxk_f.weight torch.Size([384, 1, 3, 6])

Updating key ('stages.1.blocks.0.conv.conv2_kxk.weight', 'stages.1.blocks.0.conv.conv2_kxk_t.weight', 'stages.1.blocks.0.conv.conv2_kxk_f.weight')
Updating after reshaping stages.1.blocks.0.conv.conv2_kxk_t.weight torch.Size([768, 1, 6, 3])
Updating after reshaping stages.1.blocks.0.conv.conv2_kxk_f.weight torch.Size([768, 1, 3, 6])

Updating key ('stages.1.blocks.1.conv.conv2_kxk.weight', 'stages.1.blocks.1.conv.conv2_kxk_t.weight', 'stages.1.blocks.1.conv.conv2_kxk_f.weight')
Updating after reshaping stages.1.blocks.1.conv.conv2_kxk_t.weight torch.Size([768, 1, 6, 3])
Updating after reshaping stages.1.blocks.1.conv.conv2_kxk_f.weight torch.Size([768, 1, 3, 6])

Updating key ('stages.2.blocks.0.conv.conv2_kxk.weight', 'stages.2.blocks.0.conv.conv2_kxk_t.weight', 'stages.2.blocks.0.conv.conv2_kxk_f.weight')
Updating after reshaping stages.2.blocks.0.conv.conv2_kxk_t.weight torch.Size([1536, 1, 6, 3])
Updating after reshaping stages.2.blocks.0.conv.conv2_kxk_f.weight torch.Size([1536, 1, 3, 6])

Updating key ('stages.2.blocks.1.conv.conv2_kxk.weight', 'stages.2.blocks.1.conv.conv2_kxk_t.weight', 'stages.2.blocks.1.conv.conv2_kxk_f.weight')
Updating after reshaping stages.2.blocks.1.conv.conv2_kxk_t.weight torch.Size([1536, 1, 6, 3])
Updating after reshaping stages.2.blocks.1.conv.conv2_kxk_f.weight torch.Size([1536, 1, 3, 6])

Updating key ('stages.2.blocks.2.conv.conv2_kxk.weight', 'stages.2.blocks.2.conv.conv2_kxk_t.weight', 'stages.2.blocks.2.conv.conv2_kxk_f.weight')
Updating after reshaping stages.2.blocks.2.conv.conv2_kxk_t.weight torch.Size([1536, 1, 6, 3])
Updating after reshaping stages.2.blocks.2.conv.conv2_kxk_f.weight torch.Size([1536, 1, 3, 6])

Updating key ('stages.2.blocks.3.conv.conv2_kxk.weight', 'stages.2.blocks.3.conv.conv2_kxk_t.weight', 'stages.2.blocks.3.conv.conv2_kxk_f.weight')
Updating after reshaping stages.2.blocks.3.conv.conv2_kxk_t.weight torch.Size([1536, 1, 6, 3])
Updating after reshaping stages.2.blocks.3.conv.conv2_kxk_f.weight torch.Size([1536, 1, 3, 6])

Updating key ('stages.2.blocks.4.conv.conv2_kxk.weight', 'stages.2.blocks.4.conv.conv2_kxk_t.weight', 'stages.2.blocks.4.conv.conv2_kxk_f.weight')
Updating after reshaping stages.2.blocks.4.conv.conv2_kxk_t.weight torch.Size([1536, 1, 6, 3])
Updating after reshaping stages.2.blocks.4.conv.conv2_kxk_f.weight torch.Size([1536, 1, 3, 6])

Updating key ('stages.3.blocks.0.conv.conv2_kxk.weight', 'stages.3.blocks.0.conv.conv2_kxk_t.weight', 'stages.3.blocks.0.conv.conv2_kxk_f.weight')
Updating after reshaping stages.3.blocks.0.conv.conv2_kxk_t.weight torch.Size([3072, 1, 4, 3])
Updating after reshaping stages.3.blocks.0.conv.conv2_kxk_f.weight torch.Size([3072, 1, 3, 4])

Updating key ('stages.3.blocks.1.conv.conv2_kxk.weight', 'stages.3.blocks.1.conv.conv2_kxk_t.weight', 'stages.3.blocks.1.conv.conv2_kxk_f.weight')
Updating after reshaping stages.3.blocks.1.conv.conv2_kxk_t.weight torch.Size([3072, 1, 4, 3])
Updating after reshaping stages.3.blocks.1.conv.conv2_kxk_f.weight torch.Size([3072, 1, 3, 4])
init  stem.t_f_weight
init  stages.0.blocks.0.conv.t_f_weight
init  stages.0.blocks.1.conv.t_f_weight
init  stages.1.blocks.0.conv.t_f_weight
init  stages.1.blocks.1.conv.t_f_weight
init  stages.2.blocks.0.conv.t_f_weight
init  stages.2.blocks.1.conv.t_f_weight
init  stages.2.blocks.2.conv.t_f_weight
init  stages.2.blocks.3.conv.t_f_weight
init  stages.2.blocks.4.conv.t_f_weight
init  stages.3.blocks.0.conv.t_f_weight
init  stages.3.blocks.1.conv.t_f_weight
relative_pos_keys,  ['stages.0.blocks.0.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.0.blocks.0.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.0.blocks.1.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.0.blocks.1.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.1.blocks.0.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.1.blocks.0.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.1.blocks.1.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.1.blocks.1.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.0.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.0.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.1.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.1.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.2.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.2.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.3.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.3.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.4.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.2.blocks.4.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.3.blocks.0.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.3.blocks.0.attn_grid.attn.rel_pos.relative_position_bias_table', 'stages.3.blocks.1.attn_block.attn.rel_pos.relative_position_bias_table', 'stages.3.blocks.1.attn_grid.attn.rel_pos.relative_position_bias_table']

 All the keys in params in model.state_dict except relative pos keys head.fc are missing so good to load with strict = False

 Params not init after after_skip_formats []
timm forward_features out  torch.Size([1, 527])
count_parameters  69.039975

Loading ../../pretrained_models/audioset_fullset/best_model/models/best_audio_model.pth

 Now starting validating with best model 

Val loader size  591
0/591
1/591
2/591
3/591
4/591
5/591
6/591
7/591
8/591
9/591
10/591
11/591
12/591
13/591
14/591
15/591
16/591
17/591
18/591
19/591
20/591
21/591
22/591
23/591
24/591
25/591
26/591
27/591
28/591
29/591
30/591
31/591
32/591
33/591
34/591
35/591
36/591
37/591
38/591
39/591
40/591
41/591
42/591
43/591
44/591
45/591
46/591
47/591
48/591
49/591
50/591
51/591
52/591
53/591
54/591
55/591
56/591
57/591
58/591
59/591
60/591
61/591
62/591
63/591
64/591
65/591
66/591
67/591
68/591
69/591
70/591
71/591
72/591
73/591
74/591
75/591
76/591
77/591
78/591
79/591
80/591
81/591
82/591
83/591
84/591
85/591
86/591
87/591
88/591
89/591
90/591
91/591
92/591
93/591
94/591
95/591
96/591
97/591
98/591
99/591
100/591
101/591
102/591
103/591
104/591
105/591
106/591
107/591
108/591
109/591
110/591
111/591
112/591
113/591
114/591
115/591
116/591
117/591
118/591
119/591
120/591
121/591
122/591
123/591
124/591
125/591
126/591
127/591
128/591
129/591
130/591
131/591
132/591
133/591
134/591
135/591
136/591
137/591
138/591
139/591
140/591
141/591
142/591
143/591
144/591
145/591
146/591
147/591
148/591
149/591
150/591
151/591
152/591
153/591
154/591
155/591
156/591
157/591
158/591
159/591
160/591
161/591
162/591
163/591
164/591
165/591
166/591
167/591
168/591
169/591
170/591
171/591
172/591
173/591
174/591
175/591
176/591
177/591
178/591
179/591
180/591
181/591
182/591
183/591
184/591
185/591
186/591
187/591
188/591
189/591
190/591
191/591
192/591
193/591
194/591
195/591
196/591
197/591
198/591
199/591
200/591
201/591
202/591
203/591
204/591
205/591
206/591
207/591
208/591
209/591
210/591
211/591
212/591
213/591
214/591
215/591
216/591
217/591
218/591
219/591
220/591
221/591
222/591
223/591
224/591
225/591
226/591
227/591
228/591
229/591
230/591
231/591
232/591
233/591
234/591
235/591
236/591
237/591
238/591
239/591
240/591
241/591
242/591
243/591
244/591
245/591
246/591
247/591
248/591
249/591
250/591
251/591
252/591
253/591
254/591
255/591
256/591
257/591
258/591
259/591
260/591
261/591
262/591
263/591
264/591
265/591
266/591
267/591
268/591
269/591
270/591
271/591
272/591
273/591
274/591
275/591
276/591
277/591
278/591
279/591
280/591
281/591
282/591
283/591
284/591
285/591
286/591
287/591
288/591
289/591
290/591
291/591
292/591
293/591
294/591
295/591
296/591
297/591
298/591
299/591
300/591
301/591
302/591
303/591
304/591
305/591
306/591
307/591
308/591
309/591
310/591
311/591
312/591
313/591
314/591
315/591
316/591
317/591
318/591
319/591
320/591
321/591
322/591
323/591
324/591
325/591
326/591
327/591
328/591
329/591
330/591
331/591
332/591
333/591
334/591
335/591
336/591
337/591
338/591
339/591
340/591
341/591
342/591
343/591
344/591
345/591
346/591
347/591
348/591
349/591
350/591
351/591
352/591
353/591
354/591
355/591
356/591
357/591
358/591
359/591
360/591
361/591
362/591
363/591
364/591
365/591
366/591
367/591
368/591
369/591
370/591
371/591
372/591
373/591
374/591
375/591
376/591
377/591
378/591
379/591
380/591
381/591
382/591
383/591
384/591
385/591
386/591
387/591
388/591
389/591
390/591
391/591
392/591
393/591
394/591
395/591
396/591
397/591
398/591
399/591
400/591
401/591
402/591
403/591
404/591
405/591
406/591
407/591
408/591
409/591
410/591
411/591
412/591
413/591
414/591
415/591
416/591
417/591
418/591
419/591
420/591
421/591
422/591
423/591
424/591
425/591
426/591
427/591
428/591
429/591
430/591
431/591
432/591
433/591
434/591
435/591
436/591
437/591
438/591
439/591
440/591
441/591
442/591
443/591
444/591
445/591
446/591
447/591
448/591
449/591
450/591
451/591
452/591
453/591
454/591
455/591
456/591
457/591
458/591
459/591
460/591
461/591
462/591
463/591
464/591
465/591
466/591
467/591
468/591
469/591
470/591
471/591
472/591
473/591
474/591
475/591
476/591
477/591
478/591
479/591
480/591
481/591
482/591
483/591
484/591
485/591
486/591
487/591
488/591
489/591
490/591
491/591
492/591
493/591
494/591
495/591
496/591
497/591
498/591
499/591
500/591
501/591
502/591
503/591
504/591
505/591
506/591
507/591
508/591
509/591
510/591
511/591
512/591
513/591
514/591
515/591
516/591
517/591
518/591
519/591
520/591
521/591
522/591
523/591
524/591
525/591
526/591
527/591
528/591
529/591
530/591
531/591
532/591
533/591
534/591
535/591
536/591
537/591
538/591
539/591
540/591
541/591
542/591
543/591
544/591
545/591
546/591
547/591
548/591
549/591
550/591
551/591
552/591
553/591
554/591
555/591
556/591
557/591
558/591
559/591
560/591
561/591
562/591
563/591
564/591
565/591
566/591
567/591
568/591
569/591
570/591
571/591
572/591
573/591
574/591
575/591
576/591
577/591
578/591
579/591
580/591
581/591
582/591
583/591
584/591
585/591
586/591
587/591
588/591
589/591
590/591
Val mAP: 0.48670145744698895
Validation Completed 
